---
layout:       post
title:        "马尔可夫决策过程MDP"
subtitle:     "MDP"
date:         2018-05-31 09"41:00
author:       "xuepro"
header-img:   "img/home_bg.jpg"
header-mask:  0.3
catalog:      true
multilingual: true
tags:
    - AI
     
---    

**A stochastic process** is an indexed collection of random variables $$ {X_t} $$.
 e.g., time series of weekly demands for a product
 
**A stochastic process $$ X_t $$** is said to be Markovian if and only if

$$ P(X_{t+1}=j| X_t=i,X_{t-1}=k_{t-1},X_{t-2}=k_{t-2},...X_1=k_1,X_0=k_0) = P(X_{t+1}=j|X_0=k_0) $$

   “The future is independent of the past given the present”
   
**A Markov process** (or **Markov chain**) is a **memoryless** stochastic process, i.e., a sequence of random states
$$s_1; s_2; : : :$$ with the Markov property
