---
layout:       post
title:        新书“深度学习理论、实现与实战”目录
subtitle:     新书“深度学习理论、实现与实战”目录
date:         2019-06-05 07:06:00
author:       "xuepro"
header-img:   "img/home_bg.jpg"
header-mask:  0.3
catalog:      true
multilingual: true
tags:
    - DL
---

打算写一本新书 **深度学习理论、实现与实战(Pytorch描述)** ，目录初步如下，欢迎意见和建议，比如选取什么样的案例？
注：为避免目录细节太多，很多小节的细节省略了。

 ```
第1章  基础知识       
       1.1  数学基础
          1.1.1 线性代数: 向量、矩阵、范数、特征值和特征向量
          1.1.2 函数、导数、梯度、Heisen矩阵
          1.1.3 优化
          1.1.4  概率和统计
      1.2  Python快速入门 
          1.2.1 Python介绍及环境的安装
          1.2.2 基本计算
          1.2.3 数据结构
          1.2.4 函数
          1.2.5 类和对象          
       1.3  Matplot画图 
       1.4 Numpy快速入门       
       
第2章  回归和分类：线性回归、逻辑回归、softmax回归
     2.1 什么是机器学习?
     2.2 线性回归
       2.2.1 餐车利润问题
       2.2.2 什么是线性回归？
       2.2.3 模型训练：求解假设函数       
     2.3 正规方程
     2 .4 梯度下降法
        2.4.1 梯度下降法
        2.4.2 梯度下降法的python实现
        2.4.3 调试学习率
        2.4.4 梯度验证
        2.4.5 梯度下降法的 numpy实现
        2.4.6 随机梯度下降法和批梯度下降法
        2.4.7 数据的规范化
     2.5 欠拟合和过拟合、学习曲线
     2.6 实战Kaggle比赛: 房屋价格预测
     2.7 逻辑回归
         2.7.1 二分类和逻辑回归
         2.7.2 逻辑回归的numpy实现
         2.7.3 实战：鸢尾花的分类
     2.8 softmax回归
         2.8.1 多分类和softmax回归
         2.8.2 softmax回归的numpy实现
         2.8.3 实战：MNIST手写数字识别 
        
第3章  神经网络和深度学习
     3.1 神经网络
        3.1.1 神经元
        3.1.2 激活函数
        3.1.3 神经网络       
        3.1.4 损失函数
     3.2 神经网络的训练
         3.2.1 代价函数
         3.2.2 求导：反向传播算法
               链式求导法则
               激活函数的导数
               用链式求导法则求代价函数的梯度
                反向传播算法
         3.2.3 梯度下降算法的numpy实现
     3.3 实战：3层神经网络识别MNIST手写数字
           1.3.1  MNIST手写数字集
           1.3.2  神经网络的训练
           1.3.3  神经网络的预测
     3.4 深度学习
        3.4.1  深层神经网络
        3.4.2  前向传播、反向传播和计算图
        3.4.3  实战：MNIST手写数字识别的深度学习
        3.4.4  多层神经网络的训练技巧(参数和超参数)    
     
第4章  基于PyTorch框架的深度学习
     4.1  Pytorch介绍
     4.2  房屋价格预测的Pytorh实现
     4.3  MNIST手写数字识别的Pytorch实现
        
第5章  卷积神经网络
       5.1 卷积
         1. 1  卷积和特征提取
         1.2   卷积的步长和填充
         1.3   多输入通道和多输出通道
       5.2  池化层
       5.3  卷积神经⽹络(CNN)
           5.3.1  LeNet网络
           5.3.2  参数初始化 
           5.3.3  识别MNIST手写数字
           5.3.4  CIFAR-10 图像分类     
       5.4  打开卷积神经网络的“黑盒子”
           5.4.1  卷积神经网络为什么有效
           5.4.2  卷积神经网络的可视化
           5.4.3  进一步理解卷积神经网络? 
             5.4.3.1 类显著度图
             5.4.3.2 欺骗神经网络（含对抗例子）
      5.5  卷积神经网络的典型架构
          5.5.1   AlexNet模型
          5.5.2   VGG模型
          5.5.3   NIN模型
          5.5.4   Google  Net模型
          5.5.5   残差网络ResNet
          5.5.6   稠密网络DenseNet

第6章  优化
     6.1   常用优化技巧          
          1.1  过拟合和欠拟合
          1.2  权重衰减正则化
          1.3  Dropout正则化
          1.4  批归一化
      6.2 优化算法
           2.1  动量法
           2.2  AdaGrad
           2.3  RMSProp
           2.4  AdaDelta
           2.5  Adam
      6.3  实战（待补充，可以产生对比效果）
      
第7章  循环神经网络
     7.1  文本和序列问题
     7.2  循环神经网络模型架构
     7.3  通过时间的反向传播     
     7.4  GRU和LSTM
     7.5  实战：情感分类
     7.6  注意力机制
     7.7 实战：实现机器翻译
        
第8章  生成对抗网络
      8.1  什么是生成对抗网络       
      8.2  GAN具体原理
      8.3  经典GAN结构     
      8.4  实战：生成动漫角色
      8.5  实战：实现图片域的迁移

第9章  深度学习在计算机视觉领域的应用
       9.1  目标检测
            9.1.1 什么是目标检测？
            9.1.2 经典目标检测算法介绍
            9.1.3 深度学习目标检测
            9.1.4 实战：车牌检测
       9.2 风格迁移
           9.2.1 风格迁移的原理
           9.2.2 实战：风格迁移的实现 
       9.3
           9.3.1 DeepDream的原理
           9.3.2 实战：DeepDream实现
       9.4 其他应用介绍
       
第10章  深度学习在自然语言处理领域的应用
       10.1 自然语言理解
          10.1.1 词向量
          10.1.2 传统的Word2Vec 和 FastTest
          10.1.3 新型的BERT
          10.1.4 实战： 近义词
          10.1.5 实战： 聊天机器人       
       10.2   ??? 
       10.3  其他应用介绍
  
第11章 强化学习
       11.1  什么是强化学习
       11.2 Q-Learning
       11.3  实战：Q-Learning训练flappy bird小游戏
       11.4  DQN
       11.5  实战：DQN训练flappy bird小游戏
       11.6  其他算法介绍
```
